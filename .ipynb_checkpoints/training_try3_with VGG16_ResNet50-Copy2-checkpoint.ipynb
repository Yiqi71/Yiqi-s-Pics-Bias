{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47adc055-4d94-4d26-8152-c7341a0a1679",
   "metadata": {},
   "source": [
    "prompt:\n",
    "我想用别人训练好的模型去分辨我这些图片里是什么动物，从而辅助我这个模型更理解我给不同动物图片打分的逻辑\n",
    "有没有一个能识别动物的model我能用的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030bd34-46d8-4954-b4b9-44450a773dbd",
   "metadata": {},
   "source": [
    "ResNet50 作为预训练的卷积基模型被用于提取图片的特征。通过将 include_top=False，我们去掉了原本用于分类的顶部全连接层，只保留了卷积层和池化层，提取出来的特征会传给后续的全连接层进行分类。\n",
    "\n",
    "GlobalAveragePooling2D：这一层用于池化 ResNet50 输出的特征图，它会将每个通道的特征图缩减为一个单一的数值。这个操作帮助我们减少模型的参数量和计算量。\n",
    "\n",
    "训练部分：数据被划分为训练集、验证集和测试集。然后用 fit() 训练模型，训练过程中可以通过 TensorBoard 可视化训练过程。\n",
    "\n",
    "比较两个图片：通过调整图片大小并输入到模型中，比较模型对两张图片的预测结果，得出你更喜欢的图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8f0ac-c7a2-4e2b-b35c-f8d6f0d461bd",
   "metadata": {},
   "source": [
    "1. 准备环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d5998d1f-4988-4018-bc58-8ba41af35832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84ec33-ca20-4c91-b75e-a5d4c7a920a8",
   "metadata": {},
   "source": [
    "2. 加载图片和评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f3e8f92d-983d-452c-a127-49358841ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载CSV文件\n",
    "df = pd.read_csv('dogs_manual_score.csv')\n",
    "\n",
    "# 获取图片路径和对应的评分\n",
    "image_paths = df['Photo'].apply(lambda x: os.path.join('dog_pics', x)).tolist()\n",
    "scores = df['Score'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f000af-c47a-4396-9e5d-a86e37e56038",
   "metadata": {},
   "source": [
    "3. 加载和预处理图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4602d8fd-2826-407f-86b5-547584afe837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 加载图片并进行预处理\n",
    "def load_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(256, 256))  # 读取并调整大小\n",
    "    img_array = image.img_to_array(img)  # 转换为数组\n",
    "    img_array = img_array / 255.0  # 归一化处理\n",
    "    return img_array\n",
    "\n",
    "# 处理所有图片\n",
    "images = np.array([load_image(path) for path in image_paths])\n",
    "\n",
    "# 拆分训练集和测试集（80% 训练，20% 测试）\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, scores, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4924e15-f267-4643-ac70-6e434a08ffea",
   "metadata": {},
   "source": [
    "4. 使用ResNet50提取图片特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65f7031f-5500-495e-afbe-b6da843e2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用ResNet50提取图片特征\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# 冻结ResNet50的层（不进行训练）\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff2db8c7-aa3a-4c67-8ea7-f5d7eaf3a8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 3s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2s/step\n"
     ]
    }
   ],
   "source": [
    "# 定义特征提取模型\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "# 提取训练和测试集的特征\n",
    "X_train_features = feature_extractor.predict(X_train)\n",
    "X_test_features = feature_extractor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe81d7a-b8cc-4f2e-8dcf-268c00cdeee4",
   "metadata": {},
   "source": [
    "5. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f33b60ac-09b5-4f45-94bf-7a50398e3591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_features shape: (307, 2048)\n",
      "X_test_features shape: (62, 2048)\n",
      "y_train shape: (245,)\n",
      "y_test shape: (62,)\n",
      "Number of images: 307\n",
      "Number of labels: 245\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "图像和标签数量不一致，请检查数据。",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNumber of labels:\u001b[39m\u001b[38;5;124m\"\u001b[39m, y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# 如果数量不一致，修正为相同数量\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m X_train_images\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m==\u001b[39m y_train\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m图像和标签数量不一致，请检查数据。\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# 创建数据增强器\u001b[39;00m\n\u001b[0;32m     27\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(\n\u001b[0;32m     28\u001b[0m     rotation_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m40\u001b[39m, \n\u001b[0;32m     29\u001b[0m     width_shift_range\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.2\u001b[39m, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     34\u001b[0m     fill_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     35\u001b[0m )\n",
      "\u001b[1;31mAssertionError\u001b[0m: 图像和标签数量不一致，请检查数据。"
     ]
    }
   ],
   "source": [
    "# 确保数据是float32\n",
    "X_train_features = X_train_features.astype(np.float32)\n",
    "X_test_features = X_test_features.astype(np.float32)\n",
    "\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "# 确保形状正确\n",
    "print(\"X_train_features shape:\", X_train_features.shape)  # (样本数, 特征维度)\n",
    "print(\"X_test_features shape:\", X_test_features.shape)\n",
    "print(\"y_train shape:\", y_train.shape)  # (样本数,)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# 假设 `image_paths` 包含所有图像路径\n",
    "# 假设 `load_image` 是加载图像的函数，将图像加载为numpy数组\n",
    "X_train_images = [load_image(path) for path in image_paths]\n",
    "X_train_images = np.array(X_train_images)\n",
    "\n",
    "# 检查图像和标签数量是否一致\n",
    "print(\"Number of images:\", X_train_images.shape[0])\n",
    "print(\"Number of labels:\", y_train.shape[0])\n",
    "\n",
    "# 如果数量不一致，修正为相同数量\n",
    "assert X_train_images.shape[0] == y_train.shape[0], \"图像和标签数量不一致，请检查数据。\"\n",
    "\n",
    "# 创建数据增强器\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=40, \n",
    "    width_shift_range=0.2, \n",
    "    height_shift_range=0.2, \n",
    "    shear_range=0.2, \n",
    "    zoom_range=0.2, \n",
    "    horizontal_flip=True, \n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# 在增强图像并提取特征后，确保样本数与标签数一致\n",
    "augmented_features = []\n",
    "augmented_labels = []\n",
    "\n",
    "# 定义一个变量来记录处理的批次数量\n",
    "processed_samples = 0\n",
    "\n",
    "# 遍历生成增强图像\n",
    "for batch in datagen.flow(X_train_images, y_train, batch_size=32, shuffle=False):\n",
    "    # 取出每个批次的特征\n",
    "    features_batch = model.predict(batch)  # 使用ResNet50提取增强后的图像特征\n",
    "    augmented_features.append(features_batch)\n",
    "    augmented_labels.append(y_train)  # 记录标签\n",
    "\n",
    "    # 增加处理的样本数量\n",
    "    processed_samples += batch.shape[0]\n",
    "\n",
    "    # 如果处理的样本数量达到了图像的总数，停止增强\n",
    "    if processed_samples >= len(X_train_images):\n",
    "        break\n",
    "\n",
    "# 将所有增强后的特征和标签合并\n",
    "X_train_features = np.vstack(augmented_features)\n",
    "y_train = np.concatenate(augmented_labels)\n",
    "\n",
    "# 检查增强后的数据数量是否一致\n",
    "print(\"Augmented X_train_features shape:\", X_train_features.shape)\n",
    "print(\"Augmented y_train shape:\", y_train.shape)\n",
    "\n",
    "# 训练模型\n",
    "history = score_model.fit(\n",
    "    X_train_features, y_train,  # 使用增强后的特征数据进行训练\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_features, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42ef10-335b-44eb-9e2d-30a90b04f2f4",
   "metadata": {},
   "source": [
    "6. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8bf3a530-4ca1-4d88-a6b8-f568d2a7a35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - loss: 3452.3867 - mae: 49.3787\n",
      "Model MSE: 3311.433837890625, MAE: 47.7454948425293\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "mse, mae = score_model.evaluate(X_test_features, y_test)\n",
    "print(f\"Model MSE: {mse}, MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ebafe36b-a4fe-4635-a6bb-74a798b2c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step\n",
      "Pearson correlation: -0.11869934803175151\n"
     ]
    }
   ],
   "source": [
    "# 计算皮尔逊相关系数\n",
    "y_pred = score_model.predict(X_test_features)\n",
    "correlation = np.corrcoef(y_test, y_pred.flatten())[0, 1]\n",
    "print(f'Pearson correlation: {correlation}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd9699d-9352-4f4e-8ea1-feef37391e77",
   "metadata": {},
   "source": [
    "7. 比较两张图片，预测哪个更符合你的喜好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86180524-4fc9-4ff6-86f3-9ddd2b459927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "You prefer the second image.\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('animal_pics/google-advancedsearch-2.jpg')  # 将路径替换为实际图片路径\n",
    "img2 = cv2.imread('animal_pics/google-advancedsearch-7.jpg')\n",
    "\n",
    "# 将图片转换为数组\n",
    "img1 = cv2.resize(img1, (256, 256))  # 如果使用OpenCV，需要先调整图像大小\n",
    "img1 = img1 / 255.0  # 归一化到0-1范围\n",
    "img1 = np.expand_dims(img1, axis=0)  # 增加批次维度\n",
    "\n",
    "img2 = cv2.resize(img2, (256, 256))  # 如果使用OpenCV，需要先调整图像大小\n",
    "img2 = img2 / 255.0  # 归一化到0-1范围\n",
    "img2 = np.expand_dims(img2, axis=0)  # 增加批次维度\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    # 提取图片特征\n",
    "    features1 = model.predict(img1)  # 直接传入已调整的图片\n",
    "    features2 = model.predict(img2)\n",
    "    \n",
    "    # 使用评分模型来预测评分\n",
    "    score1 = score_model.predict(features1)\n",
    "    score2 = score_model.predict(features2)\n",
    "    \n",
    "    if score1 > score2:\n",
    "        return \"You prefer the first image.\"\n",
    "    else:\n",
    "        return \"You prefer the second image.\"\n",
    "\n",
    "# 假设img1和img2是你要比较的两张图片\n",
    "\n",
    "print(compare_images(img1, img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc10e1-d410-4204-8bf6-88497fce1bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classificationtry1",
   "language": "python",
   "name": "classificationtry1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
