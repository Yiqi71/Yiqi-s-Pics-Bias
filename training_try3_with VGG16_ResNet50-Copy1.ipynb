{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47adc055-4d94-4d26-8152-c7341a0a1679",
   "metadata": {},
   "source": [
    "prompt:\n",
    "我想用别人训练好的模型去分辨我这些图片里是什么动物，从而辅助我这个模型更理解我给不同动物图片打分的逻辑\n",
    "有没有一个能识别动物的model我能用的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030bd34-46d8-4954-b4b9-44450a773dbd",
   "metadata": {},
   "source": [
    "ResNet50 作为预训练的卷积基模型被用于提取图片的特征。通过将 include_top=False，我们去掉了原本用于分类的顶部全连接层，只保留了卷积层和池化层，提取出来的特征会传给后续的全连接层进行分类。\n",
    "\n",
    "GlobalAveragePooling2D：这一层用于池化 ResNet50 输出的特征图，它会将每个通道的特征图缩减为一个单一的数值。这个操作帮助我们减少模型的参数量和计算量。\n",
    "\n",
    "训练部分：数据被划分为训练集、验证集和测试集。然后用 fit() 训练模型，训练过程中可以通过 TensorBoard 可视化训练过程。\n",
    "\n",
    "比较两个图片：通过调整图片大小并输入到模型中，比较模型对两张图片的预测结果，得出你更喜欢的图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8f0ac-c7a2-4e2b-b35c-f8d6f0d461bd",
   "metadata": {},
   "source": [
    "1. 准备环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5998d1f-4988-4018-bc58-8ba41af35832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84ec33-ca20-4c91-b75e-a5d4c7a920a8",
   "metadata": {},
   "source": [
    "2. 加载图片和评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3e8f92d-983d-452c-a127-49358841ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载CSV文件\n",
    "df = pd.read_csv('dogs_manual_score.csv')\n",
    "\n",
    "# 获取图片路径和对应的评分\n",
    "image_paths = df['Photo'].apply(lambda x: os.path.join('dog_pics', x)).tolist()\n",
    "scores = df['Score'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f000af-c47a-4396-9e5d-a86e37e56038",
   "metadata": {},
   "source": [
    "3. 加载和预处理图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4602d8fd-2826-407f-86b5-547584afe837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 加载图片并进行预处理\n",
    "def load_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(256, 256))  # 读取并调整大小\n",
    "    img_array = image.img_to_array(img)  # 转换为数组\n",
    "    img_array = img_array / 255.0  # 归一化处理\n",
    "    return img_array\n",
    "\n",
    "# 处理所有图片\n",
    "images = np.array([load_image(path) for path in image_paths])\n",
    "\n",
    "# 拆分训练集和测试集（80% 训练，20% 测试）\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, scores, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4924e15-f267-4643-ac70-6e434a08ffea",
   "metadata": {},
   "source": [
    "4. 使用ResNet50提取图片特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65f7031f-5500-495e-afbe-b6da843e2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用ResNet50提取图片特征\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# 冻结ResNet50的层（不进行训练）\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff2db8c7-aa3a-4c67-8ea7-f5d7eaf3a8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 2s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# 定义特征提取模型\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "# 提取训练和测试集的特征\n",
    "X_train_features = feature_extractor.predict(X_train)\n",
    "X_test_features = feature_extractor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe81d7a-b8cc-4f2e-8dcf-268c00cdeee4",
   "metadata": {},
   "source": [
    "5. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f33b60ac-09b5-4f45-94bf-7a50398e3591",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_features shape: (245, 2048)\n",
      "X_test_features shape: (62, 2048)\n",
      "y_train shape: (245,)\n",
      "y_test shape: (62,)\n",
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 94ms/step - loss: 953979.6250 - mae: 975.9830 - val_loss: 916458.4375 - val_mae: 956.4792\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 907236.0000 - mae: 951.7520 - val_loss: 845894.9375 - val_mae: 918.8423\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - loss: 825136.1875 - mae: 907.4749 - val_loss: 721895.6875 - val_mae: 848.6623\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 681153.6250 - mae: 824.1739 - val_loss: 537553.7500 - val_mae: 731.9694\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 489372.0000 - mae: 697.3726 - val_loss: 310358.9688 - val_mae: 555.2874\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 259088.7812 - mae: 504.3525 - val_loss: 102434.4297 - val_mae: 316.1381\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 72375.6484 - mae: 257.4394 - val_loss: 5829.9019 - val_mae: 60.5872\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 4372.9805 - mae: 53.3293 - val_loss: 18288.0918 - val_mae: 121.1428\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - loss: 18142.0312 - mae: 124.1164 - val_loss: 15812.0859 - val_mae: 111.3900\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 11165.6270 - mae: 87.9542 - val_loss: 4011.7363 - val_mae: 51.6805\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 2715.5576 - mae: 42.2053 - val_loss: 3965.6401 - val_mae: 50.3488\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3745.5903 - mae: 50.2989 - val_loss: 3886.0947 - val_mae: 49.9808\n",
      "Epoch 13/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 3604.9788 - mae: 47.7138 - val_loss: 3313.9351 - val_mae: 48.2868\n",
      "Epoch 14/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2829.6711 - mae: 41.4820 - val_loss: 3626.7180 - val_mae: 49.5164\n",
      "Epoch 15/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 2782.5801 - mae: 42.5414 - val_loss: 3530.2627 - val_mae: 49.0511\n",
      "Epoch 16/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 2911.0417 - mae: 43.3498 - val_loss: 3319.2261 - val_mae: 48.1406\n",
      "Epoch 17/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2799.2178 - mae: 41.8186 - val_loss: 3262.9387 - val_mae: 47.8555\n",
      "Epoch 18/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - loss: 2847.5044 - mae: 42.1300 - val_loss: 3286.9019 - val_mae: 47.8750\n",
      "Epoch 19/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2781.8242 - mae: 42.3606 - val_loss: 3283.0620 - val_mae: 47.7853\n",
      "Epoch 20/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2628.7737 - mae: 41.6806 - val_loss: 3269.7073 - val_mae: 47.6569\n",
      "Training history: {'loss': [945517.0625, 895963.1875, 804550.375, 654923.6875, 449766.59375, 221946.90625, 51783.94140625, 5941.8505859375, 17666.95703125, 8065.54150390625, 3095.869384765625, 3994.581787109375, 3186.630859375, 2772.199462890625, 2830.97119140625, 2725.21923828125, 2713.207763671875, 2702.51220703125, 2663.76611328125, 2652.666015625], 'mae': [971.5951538085938, 945.7459106445312, 895.9798583984375, 807.8770751953125, 667.74169921875, 465.083984375, 210.3551788330078, 60.77305603027344, 120.8404769897461, 72.77040100097656, 45.48616409301758, 51.65046310424805, 45.351985931396484, 41.82059097290039, 42.51417541503906, 41.447303771972656, 41.3576545715332, 41.280914306640625, 40.91412353515625, 40.849761962890625], 'val_loss': [916458.4375, 845894.9375, 721895.6875, 537553.75, 310358.96875, 102434.4296875, 5829.90185546875, 18288.091796875, 15812.0859375, 4011.736328125, 3965.64013671875, 3886.0947265625, 3313.93505859375, 3626.718017578125, 3530.2626953125, 3319.22607421875, 3262.938720703125, 3286.90185546875, 3283.06201171875, 3269.707275390625], 'val_mae': [956.4791870117188, 918.8423461914062, 848.6622924804688, 731.9693603515625, 555.287353515625, 316.1380920410156, 60.58715057373047, 121.14278411865234, 111.3900375366211, 51.68049621582031, 50.34878921508789, 49.980751037597656, 48.2867546081543, 49.516395568847656, 49.0511360168457, 48.140621185302734, 47.855533599853516, 47.87496566772461, 47.78528594970703, 47.656890869140625]}\n"
     ]
    }
   ],
   "source": [
    "# 确保数据类型是 float32\n",
    "X_train_features = X_train_features.astype(np.float32)\n",
    "X_test_features = X_test_features.astype(np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "# 打印数据形状，确保它是正确的\n",
    "print(\"X_train_features shape:\", X_train_features.shape)  # 例如 (num_samples, feature_dim)\n",
    "print(\"X_test_features shape:\", X_test_features.shape)\n",
    "print(\"y_train shape:\", y_train.shape)  # 例如 (num_samples,)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# 构建评分预测模型（回归模型）\n",
    "score_model = Sequential([\n",
    "    Input(shape=(X_train_features.shape[1],)),  # 输入是 ResNet50 提取的特征\n",
    "    Dense(256, activation='relu'),  # 隐藏层 1\n",
    "    Dense(128, activation='relu'),  # 隐藏层 2\n",
    "    Dense(1)  # 输出层：预测评分\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "score_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# 训练模型\n",
    "history = score_model.fit(\n",
    "    X_train_features, y_train,  # 训练数据\n",
    "    epochs=20,  # 训练轮数\n",
    "    batch_size=32,  # 批大小\n",
    "    validation_data=(X_test_features, y_test)  # 验证集\n",
    ")\n",
    "\n",
    "# 可选：输出训练过程中每个epoch的损失和 MAE\n",
    "print(\"Training history:\", history.history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42ef10-335b-44eb-9e2d-30a90b04f2f4",
   "metadata": {},
   "source": [
    "6. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "033d05e3-271e-4c8e-ba05-08025de44455",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "score_model = load_model('score_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bf3a530-4ca1-4d88-a6b8-f568d2a7a35d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] Unable to synchronously open file (unable to open file: name = 'path/to/your/score_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m score_model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpath/to/your/score_model.h5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;66;03m# 评估模型\u001b[39;00m\n\u001b[0;32m      3\u001b[0m mse, mae \u001b[38;5;241m=\u001b[39m score_model\u001b[38;5;241m.\u001b[39mevaluate(X_test_features, y_test)\n",
      "File \u001b[1;32mE:\\纽大\\Useless Machines\\Yiqi's Pics Bias\\classificationtry1\\lib\\site-packages\\keras\\src\\saving\\saving_api.py:196\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, safe_mode)\u001b[0m\n\u001b[0;32m    189\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m saving_lib\u001b[38;5;241m.\u001b[39mload_model(\n\u001b[0;32m    190\u001b[0m         filepath,\n\u001b[0;32m    191\u001b[0m         custom_objects\u001b[38;5;241m=\u001b[39mcustom_objects,\n\u001b[0;32m    192\u001b[0m         \u001b[38;5;28mcompile\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mcompile\u001b[39m,\n\u001b[0;32m    193\u001b[0m         safe_mode\u001b[38;5;241m=\u001b[39msafe_mode,\n\u001b[0;32m    194\u001b[0m     )\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n\u001b[1;32m--> 196\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlegacy_h5_format\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_model_from_hdf5\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_objects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcustom_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcompile\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mcompile\u001b[39;49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.keras\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    201\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile not found: filepath=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    202\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease ensure the file is an accessible `.keras` \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzip file.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    204\u001b[0m     )\n",
      "File \u001b[1;32mE:\\纽大\\Useless Machines\\Yiqi's Pics Bias\\classificationtry1\\lib\\site-packages\\keras\\src\\legacy\\saving\\legacy_h5_format.py:116\u001b[0m, in \u001b[0;36mload_model_from_hdf5\u001b[1;34m(filepath, custom_objects, compile)\u001b[0m\n\u001b[0;32m    114\u001b[0m opened_new_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath, h5py\u001b[38;5;241m.\u001b[39mFile)\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m opened_new_file:\n\u001b[1;32m--> 116\u001b[0m     f \u001b[38;5;241m=\u001b[39m \u001b[43mh5py\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFile\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    118\u001b[0m     f \u001b[38;5;241m=\u001b[39m filepath\n",
      "File \u001b[1;32mE:\\纽大\\Useless Machines\\Yiqi's Pics Bias\\classificationtry1\\lib\\site-packages\\h5py\\_hl\\files.py:564\u001b[0m, in \u001b[0;36mFile.__init__\u001b[1;34m(self, name, mode, driver, libver, userblock_size, swmr, rdcc_nslots, rdcc_nbytes, rdcc_w0, track_order, fs_strategy, fs_persist, fs_threshold, fs_page_size, page_buf_size, min_meta_keep, min_raw_keep, locking, alignment_threshold, alignment_interval, meta_block_size, **kwds)\u001b[0m\n\u001b[0;32m    555\u001b[0m     fapl \u001b[38;5;241m=\u001b[39m make_fapl(driver, libver, rdcc_nslots, rdcc_nbytes, rdcc_w0,\n\u001b[0;32m    556\u001b[0m                      locking, page_buf_size, min_meta_keep, min_raw_keep,\n\u001b[0;32m    557\u001b[0m                      alignment_threshold\u001b[38;5;241m=\u001b[39malignment_threshold,\n\u001b[0;32m    558\u001b[0m                      alignment_interval\u001b[38;5;241m=\u001b[39malignment_interval,\n\u001b[0;32m    559\u001b[0m                      meta_block_size\u001b[38;5;241m=\u001b[39mmeta_block_size,\n\u001b[0;32m    560\u001b[0m                      \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    561\u001b[0m     fcpl \u001b[38;5;241m=\u001b[39m make_fcpl(track_order\u001b[38;5;241m=\u001b[39mtrack_order, fs_strategy\u001b[38;5;241m=\u001b[39mfs_strategy,\n\u001b[0;32m    562\u001b[0m                      fs_persist\u001b[38;5;241m=\u001b[39mfs_persist, fs_threshold\u001b[38;5;241m=\u001b[39mfs_threshold,\n\u001b[0;32m    563\u001b[0m                      fs_page_size\u001b[38;5;241m=\u001b[39mfs_page_size)\n\u001b[1;32m--> 564\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mmake_fid\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserblock_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfcpl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mswmr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mswmr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    566\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(libver, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[0;32m    567\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_libver \u001b[38;5;241m=\u001b[39m libver\n",
      "File \u001b[1;32mE:\\纽大\\Useless Machines\\Yiqi's Pics Bias\\classificationtry1\\lib\\site-packages\\h5py\\_hl\\files.py:238\u001b[0m, in \u001b[0;36mmake_fid\u001b[1;34m(name, mode, userblock_size, fapl, fcpl, swmr)\u001b[0m\n\u001b[0;32m    236\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m swmr \u001b[38;5;129;01mand\u001b[39;00m swmr_support:\n\u001b[0;32m    237\u001b[0m         flags \u001b[38;5;241m|\u001b[39m\u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mACC_SWMR_READ\n\u001b[1;32m--> 238\u001b[0m     fid \u001b[38;5;241m=\u001b[39m \u001b[43mh5f\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfapl\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfapl\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mr+\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m    240\u001b[0m     fid \u001b[38;5;241m=\u001b[39m h5f\u001b[38;5;241m.\u001b[39mopen(name, h5f\u001b[38;5;241m.\u001b[39mACC_RDWR, fapl\u001b[38;5;241m=\u001b[39mfapl)\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mh5py\\\\h5f.pyx:102\u001b[0m, in \u001b[0;36mh5py.h5f.open\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] Unable to synchronously open file (unable to open file: name = 'path/to/your/score_model.h5', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)"
     ]
    }
   ],
   "source": [
    "score_model = load_model('path/to/your/score_model.h5')\n",
    "# 评估模型\n",
    "mse, mae = score_model.evaluate(X_test_features, y_test)\n",
    "print(f\"Model MSE: {mse}, MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebafe36b-a4fe-4635-a6bb-74a798b2c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "Pearson correlation: -0.11761570693719317\n"
     ]
    }
   ],
   "source": [
    "# 计算皮尔逊相关系数\n",
    "y_pred = score_model.predict(X_test_features)\n",
    "correlation = np.corrcoef(y_test, y_pred.flatten())[0, 1]\n",
    "print(f'Pearson correlation: {correlation}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd9699d-9352-4f4e-8ea1-feef37391e77",
   "metadata": {},
   "source": [
    "7. 比较两张图片，预测哪个更符合你的喜好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86180524-4fc9-4ff6-86f3-9ddd2b459927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 256, 256, 3)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 325ms/step\n",
      "提取的特征形状: (1, 2048)\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 311ms/step\n",
      "[[0.       0.       0.       ... 2.160856 0.       0.      ]]\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('animal_pics/google-advancedsearch-2.jpg')  # 将路径替换为实际图片路径\n",
    "print(score_model.input_shape)\n",
    "# 将图片转换为数组\n",
    "img1 = cv2.resize(img1, (256, 256))  # 如果使用OpenCV，需要先调整图像大小\n",
    "img1 = img1 / 255.0  # 归一化到0-1范围\n",
    "img1 = np.expand_dims(img1, axis=0)  # 增加批次维度\n",
    "\n",
    "\n",
    "features1 = feature_extractor.predict(img1)  # 直接传入已调整的图片\n",
    "print(f\"提取的特征形状: {features1.shape}\")\n",
    "    \n",
    "    # 使用评分模型来预测评分\n",
    "score1 = score_model.predict(img1)\n",
    "\n",
    "\n",
    "print(score1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7131b77-ab2a-47ef-b3fb-0f58e0ef1d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classificationtry1",
   "language": "python",
   "name": "classificationtry1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
