{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47adc055-4d94-4d26-8152-c7341a0a1679",
   "metadata": {},
   "source": [
    "prompt:\n",
    "我想用别人训练好的模型去分辨我这些图片里是什么动物，从而辅助我这个模型更理解我给不同动物图片打分的逻辑\n",
    "有没有一个能识别动物的model我能用的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030bd34-46d8-4954-b4b9-44450a773dbd",
   "metadata": {},
   "source": [
    "ResNet50 作为预训练的卷积基模型被用于提取图片的特征。通过将 include_top=False，我们去掉了原本用于分类的顶部全连接层，只保留了卷积层和池化层，提取出来的特征会传给后续的全连接层进行分类。\n",
    "\n",
    "GlobalAveragePooling2D：这一层用于池化 ResNet50 输出的特征图，它会将每个通道的特征图缩减为一个单一的数值。这个操作帮助我们减少模型的参数量和计算量。\n",
    "\n",
    "训练部分：数据被划分为训练集、验证集和测试集。然后用 fit() 训练模型，训练过程中可以通过 TensorBoard 可视化训练过程。\n",
    "\n",
    "比较两个图片：通过调整图片大小并输入到模型中，比较模型对两张图片的预测结果，得出你更喜欢的图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8f0ac-c7a2-4e2b-b35c-f8d6f0d461bd",
   "metadata": {},
   "source": [
    "1. 准备环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d5998d1f-4988-4018-bc58-8ba41af35832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers import Dense, Flatten, Input\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84ec33-ca20-4c91-b75e-a5d4c7a920a8",
   "metadata": {},
   "source": [
    "2. 加载图片和评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f3e8f92d-983d-452c-a127-49358841ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载CSV文件\n",
    "df = pd.read_csv('dogs_manual_score.csv')\n",
    "\n",
    "# 获取图片路径和对应的评分（更改为分类标签）\n",
    "image_paths = df['Photo'].apply(lambda x: os.path.join('dog_pics', x)).tolist()\n",
    "labels = df['Score'].apply(lambda x: 'like' if x == 1 else ('soso' if x == 0 else 'dont like')).tolist()\n",
    "\n",
    "# 将分类标签转换为数字编码\n",
    "label_map = {'like': 0, 'soso': 1, 'dont like': 2}\n",
    "y_labels = np.array([label_map[label] for label in labels])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f000af-c47a-4396-9e5d-a86e37e56038",
   "metadata": {},
   "source": [
    "3. 加载和预处理图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4602d8fd-2826-407f-86b5-547584afe837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 加载图片并进行预处理\n",
    "def load_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(256, 256))  # 读取并调整大小\n",
    "    img_array = image.img_to_array(img)  # 转换为数组\n",
    "    img_array = img_array / 255.0  # 归一化处理\n",
    "    return img_array\n",
    "\n",
    "# 处理所有图片\n",
    "images = np.array([load_image(path) for path in image_paths])\n",
    "\n",
    "# 拆分训练集和测试集（80% 训练，20% 测试）\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, y_labels, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4924e15-f267-4643-ac70-6e434a08ffea",
   "metadata": {},
   "source": [
    "4. 使用ResNet50提取图片特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65f7031f-5500-495e-afbe-b6da843e2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用ResNet50提取图片特征\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# 冻结ResNet50的层（不进行训练）\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff2db8c7-aa3a-4c67-8ea7-f5d7eaf3a8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 2s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# 定义特征提取模型\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "# 提取训练和测试集的特征\n",
    "X_train_features = feature_extractor.predict(X_train)\n",
    "X_test_features = feature_extractor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe81d7a-b8cc-4f2e-8dcf-268c00cdeee4",
   "metadata": {},
   "source": [
    "5. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f33b60ac-09b5-4f45-94bf-7a50398e3591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 81ms/step - accuracy: 0.6829 - loss: 0.9623 - val_accuracy: 1.0000 - val_loss: 5.3836e-08\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 1.0000 - loss: 1.7720e-08 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 13/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 14/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 15/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 16/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 17/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 18/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 19/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n",
      "Epoch 20/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 1.0000 - loss: 0.0000e+00 - val_accuracy: 1.0000 - val_loss: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "# 确保数据是float32\n",
    "X_train_features = X_train_features.astype(np.float32)\n",
    "X_test_features = X_test_features.astype(np.float32)\n",
    "\n",
    "# 创建分类模型\n",
    "score_model = tf.keras.Sequential([\n",
    "    Input(shape=(X_train_features.shape[1],)),  # 输入层，指定特征的维度\n",
    "    Dense(512, activation='relu'),\n",
    "    Dense(3, activation='softmax')  # 输出3个类别\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "score_model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 训练模型\n",
    "history = score_model.fit(\n",
    "    X_train_features, y_train,  # 使用提取的特征数据进行训练\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test_features, y_test)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42ef10-335b-44eb-9e2d-30a90b04f2f4",
   "metadata": {},
   "source": [
    "6. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8bf3a530-4ca1-4d88-a6b8-f568d2a7a35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 1.0000 - loss: 0.0000e+00\n",
      "Model Loss: 0.0, Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "loss, accuracy = score_model.evaluate(X_test_features, y_test)\n",
    "print(f\"Model Loss: {loss}, Accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ebafe36b-a4fe-4635-a6bb-74a798b2c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
      "Classification accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# 计算准确率\n",
    "y_pred = np.argmax(score_model.predict(X_test_features), axis=1)  # 获取预测类别\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f'Classification accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd9699d-9352-4f4e-8ea1-feef37391e77",
   "metadata": {},
   "source": [
    "7. 比较两张图片，预测哪个更符合你的喜好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "86180524-4fc9-4ff6-86f3-9ddd2b459927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 249ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step\n",
      "The image is predicted as: dont like\n"
     ]
    }
   ],
   "source": [
    "# 加载和预处理图像\n",
    "def load_and_preprocess_image(img_path):\n",
    "    img = image.load_img(img_path, target_size=(256, 256))  # 读取并调整大小\n",
    "    img_array = image.img_to_array(img)  # 转换为数组\n",
    "    img_array = img_array / 255.0  # 归一化处理\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # 增加批次维度\n",
    "    img_array = preprocess_input(img_array)  # 使用ResNet50的预处理函数\n",
    "    return img_array\n",
    "\n",
    "# 用于预测单张图片的类别\n",
    "def predict_image(img_path):\n",
    "    # 加载和预处理图片\n",
    "    img_array = load_and_preprocess_image(img_path)\n",
    "\n",
    "    # 提取图片特征\n",
    "    features = feature_extractor.predict(img_array)\n",
    "\n",
    "    # 使用训练好的分类模型进行预测\n",
    "    prediction = score_model.predict(features)\n",
    "    \n",
    "    # 获取预测的类别（最大概率的类）\n",
    "    predicted_class = np.argmax(prediction, axis=1)\n",
    "    \n",
    "    # 反向映射类别数字为标签\n",
    "    class_labels = {0: 'like', 1: 'soso', 2: 'dont like'}\n",
    "    predicted_label = class_labels[predicted_class[0]]\n",
    "\n",
    "    print(f\"The image is predicted as: {predicted_label}\")\n",
    "\n",
    "# 测试新的图片\n",
    "img_path = \"E:/纽大/Useless Machines/Yiqi's Pics Bias/dog_likeOrNot/like/3361739.jpg\"  # 替换为你要测试的图片路径\n",
    "predict_image(img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc10e1-d410-4204-8bf6-88497fce1bb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classificationtry1",
   "language": "python",
   "name": "classificationtry1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
