{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47adc055-4d94-4d26-8152-c7341a0a1679",
   "metadata": {},
   "source": [
    "prompt:\n",
    "我想用别人训练好的模型去分辨我这些图片里是什么动物，从而辅助我这个模型更理解我给不同动物图片打分的逻辑\n",
    "有没有一个能识别动物的model我能用的"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6030bd34-46d8-4954-b4b9-44450a773dbd",
   "metadata": {},
   "source": [
    "ResNet50 作为预训练的卷积基模型被用于提取图片的特征。通过将 include_top=False，我们去掉了原本用于分类的顶部全连接层，只保留了卷积层和池化层，提取出来的特征会传给后续的全连接层进行分类。\n",
    "\n",
    "GlobalAveragePooling2D：这一层用于池化 ResNet50 输出的特征图，它会将每个通道的特征图缩减为一个单一的数值。这个操作帮助我们减少模型的参数量和计算量。\n",
    "\n",
    "训练部分：数据被划分为训练集、验证集和测试集。然后用 fit() 训练模型，训练过程中可以通过 TensorBoard 可视化训练过程。\n",
    "\n",
    "比较两个图片：通过调整图片大小并输入到模型中，比较模型对两张图片的预测结果，得出你更喜欢的图片。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a8f0ac-c7a2-4e2b-b35c-f8d6f0d461bd",
   "metadata": {},
   "source": [
    "1. 准备环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d5998d1f-4988-4018-bc58-8ba41af35832",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Input\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a84ec33-ca20-4c91-b75e-a5d4c7a920a8",
   "metadata": {},
   "source": [
    "2. 加载图片和评分"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f3e8f92d-983d-452c-a127-49358841ec21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载CSV文件\n",
    "df = pd.read_csv('dogs_manual_score.csv')\n",
    "\n",
    "# 获取图片路径和对应的评分\n",
    "image_paths = df['Photo'].apply(lambda x: os.path.join('dog_pics', x)).tolist()\n",
    "scores = df['Score'].tolist()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f000af-c47a-4396-9e5d-a86e37e56038",
   "metadata": {},
   "source": [
    "3. 加载和预处理图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4602d8fd-2826-407f-86b5-547584afe837",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 加载图片并进行预处理\n",
    "def load_image(image_path):\n",
    "    img = image.load_img(image_path, target_size=(256, 256))  # 读取并调整大小\n",
    "    img_array = image.img_to_array(img)  # 转换为数组\n",
    "    img_array = img_array / 255.0  # 归一化处理\n",
    "    return img_array\n",
    "\n",
    "# 处理所有图片\n",
    "images = np.array([load_image(path) for path in image_paths])\n",
    "\n",
    "# 拆分训练集和测试集（80% 训练，20% 测试）\n",
    "X_train, X_test, y_train, y_test = train_test_split(images, scores, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4924e15-f267-4643-ac70-6e434a08ffea",
   "metadata": {},
   "source": [
    "4. 使用ResNet50提取图片特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "65f7031f-5500-495e-afbe-b6da843e2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用ResNet50提取图片特征\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(256, 256, 3))\n",
    "\n",
    "# 冻结ResNet50的层（不进行训练）\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff2db8c7-aa3a-4c67-8ea7-f5d7eaf3a8bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 2s/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1s/step\n"
     ]
    }
   ],
   "source": [
    "# 定义特征提取模型\n",
    "feature_extractor = Model(inputs=base_model.input, outputs=GlobalAveragePooling2D()(base_model.output))\n",
    "\n",
    "# 提取训练和测试集的特征\n",
    "X_train_features = feature_extractor.predict(X_train)\n",
    "X_test_features = feature_extractor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe81d7a-b8cc-4f2e-8dcf-268c00cdeee4",
   "metadata": {},
   "source": [
    "5. 训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f33b60ac-09b5-4f45-94bf-7a50398e3591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train_features shape: (245, 2048)\n",
      "X_test_features shape: (62, 2048)\n",
      "y_train shape: (245,)\n",
      "y_test shape: (62,)\n",
      "Epoch 1/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 69ms/step - loss: 953623.9375 - mae: 975.8431 - val_loss: 917604.5625 - val_mae: 957.0781\n",
      "Epoch 2/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 913490.4375 - mae: 955.0257 - val_loss: 846077.9375 - val_mae: 918.9415\n",
      "Epoch 3/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - loss: 824882.2500 - mae: 907.2830 - val_loss: 718225.6875 - val_mae: 846.4952\n",
      "Epoch 4/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - loss: 688844.8125 - mae: 828.5049 - val_loss: 527675.9375 - val_mae: 725.1823\n",
      "Epoch 5/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - loss: 483215.7812 - mae: 692.5579 - val_loss: 295464.9688 - val_mae: 541.6815\n",
      "Epoch 6/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - loss: 248934.6250 - mae: 493.5504 - val_loss: 89174.1797 - val_mae: 294.3029\n",
      "Epoch 7/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - loss: 63257.5977 - mae: 237.2917 - val_loss: 4059.0054 - val_mae: 50.9412\n",
      "Epoch 8/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4849.9790 - mae: 55.2572 - val_loss: 20731.2852 - val_mae: 130.1857\n",
      "Epoch 9/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 19966.9609 - mae: 128.2271 - val_loss: 13950.0908 - val_mae: 103.6179\n",
      "Epoch 10/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 34ms/step - loss: 8630.4453 - mae: 75.7589 - val_loss: 3635.7314 - val_mae: 49.7711\n",
      "Epoch 11/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - loss: 2961.2134 - mae: 43.2180 - val_loss: 4230.2432 - val_mae: 51.5177\n",
      "Epoch 12/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 4115.5649 - mae: 52.6075 - val_loss: 3787.5061 - val_mae: 49.6009\n",
      "Epoch 13/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3261.2524 - mae: 45.4012 - val_loss: 3351.0811 - val_mae: 48.5287\n",
      "Epoch 14/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - loss: 3202.1965 - mae: 44.7650 - val_loss: 3672.8850 - val_mae: 49.7650\n",
      "Epoch 15/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2756.4438 - mae: 42.2627 - val_loss: 3497.2913 - val_mae: 48.9464\n",
      "Epoch 16/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2825.4119 - mae: 41.9104 - val_loss: 3333.9280 - val_mae: 48.2566\n",
      "Epoch 17/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2363.1870 - mae: 39.1829 - val_loss: 3282.4622 - val_mae: 48.0045\n",
      "Epoch 18/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step - loss: 2632.8120 - mae: 41.4749 - val_loss: 3274.9021 - val_mae: 47.8967\n",
      "Epoch 19/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step - loss: 2767.0991 - mae: 41.6003 - val_loss: 3295.1936 - val_mae: 47.8847\n",
      "Epoch 20/20\n",
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - loss: 2618.3186 - mae: 40.5278 - val_loss: 3302.7727 - val_mae: 47.8252\n",
      "Training history: {'loss': [945943.125, 897177.0, 803176.6875, 649225.8125, 437744.40625, 207621.484375, 42894.19921875, 7644.30419921875, 18006.326171875, 6608.046875, 3345.24853515625, 4104.66845703125, 3078.01611328125, 2785.669921875, 2854.421875, 2718.539794921875, 2698.05908203125, 2698.060302734375, 2678.7939453125, 2662.91943359375], 'mae': [971.8192138671875, 946.3079833984375, 895.2225341796875, 803.9420776367188, 658.25341796875, 448.0915222167969, 186.7113800048828, 70.53562927246094, 121.68535614013672, 65.2158432006836, 46.526824951171875, 52.576934814453125, 44.11924743652344, 42.056793212890625, 42.651817321777344, 41.302337646484375, 41.077091217041016, 41.23657989501953, 41.04051971435547, 40.92497253417969], 'val_loss': [917604.5625, 846077.9375, 718225.6875, 527675.9375, 295464.96875, 89174.1796875, 4059.00537109375, 20731.28515625, 13950.0908203125, 3635.7314453125, 4230.2431640625, 3787.506103515625, 3351.0810546875, 3672.885009765625, 3497.291259765625, 3333.927978515625, 3282.462158203125, 3274.902099609375, 3295.193603515625, 3302.772705078125], 'val_mae': [957.078125, 918.9415283203125, 846.4952392578125, 725.1823120117188, 541.6814575195312, 294.30291748046875, 50.941158294677734, 130.18568420410156, 103.6179428100586, 49.771060943603516, 51.51766586303711, 49.60091781616211, 48.52873992919922, 49.76497268676758, 48.94635772705078, 48.25655746459961, 48.00446319580078, 47.89665603637695, 47.884708404541016, 47.82524871826172]}\n"
     ]
    }
   ],
   "source": [
    "# 确保数据类型是 float32\n",
    "X_train_features = X_train_features.astype(np.float32)\n",
    "X_test_features = X_test_features.astype(np.float32)\n",
    "y_train = np.array(y_train, dtype=np.float32)\n",
    "y_test = np.array(y_test, dtype=np.float32)\n",
    "\n",
    "# 打印数据形状，确保它是正确的\n",
    "print(\"X_train_features shape:\", X_train_features.shape)  # 例如 (num_samples, feature_dim)\n",
    "print(\"X_test_features shape:\", X_test_features.shape)\n",
    "print(\"y_train shape:\", y_train.shape)  # 例如 (num_samples,)\n",
    "print(\"y_test shape:\", y_test.shape)\n",
    "\n",
    "# 构建评分预测模型（回归模型）\n",
    "score_model = Sequential([\n",
    "    Input(shape=(X_train_features.shape[1],)),  # 输入是 ResNet50 提取的特征\n",
    "    Dense(256, activation='relu'),  # 隐藏层 1\n",
    "    Dense(128, activation='relu'),  # 隐藏层 2\n",
    "    Dense(1)  # 输出层：预测评分\n",
    "])\n",
    "\n",
    "# 编译模型\n",
    "score_model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "# 训练模型\n",
    "history = score_model.fit(\n",
    "    X_train_features, y_train,  # 训练数据\n",
    "    epochs=20,  # 训练轮数\n",
    "    batch_size=32,  # 批大小\n",
    "    validation_data=(X_test_features, y_test)  # 验证集\n",
    ")\n",
    "\n",
    "# 可选：输出训练过程中每个epoch的损失和 MAE\n",
    "print(\"Training history:\", history.history)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f42ef10-335b-44eb-9e2d-30a90b04f2f4",
   "metadata": {},
   "source": [
    "6. 模型评估"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8bf3a530-4ca1-4d88-a6b8-f568d2a7a35d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - loss: 3436.8369 - mae: 49.4441\n",
      "Model MSE: 3302.772705078125, MAE: 47.82524871826172\n"
     ]
    }
   ],
   "source": [
    "# 评估模型\n",
    "mse, mae = score_model.evaluate(X_test_features, y_test)\n",
    "print(f\"Model MSE: {mse}, MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ebafe36b-a4fe-4635-a6bb-74a798b2c55a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m2/2\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step\n",
      "Pearson correlation: -0.11759173664476538\n"
     ]
    }
   ],
   "source": [
    "# 计算皮尔逊相关系数\n",
    "y_pred = score_model.predict(X_test_features)\n",
    "correlation = np.corrcoef(y_test, y_pred.flatten())[0, 1]\n",
    "print(f'Pearson correlation: {correlation}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bd9699d-9352-4f4e-8ea1-feef37391e77",
   "metadata": {},
   "source": [
    "7. 比较两张图片，预测哪个更符合你的喜好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43384684",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 17\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# 测试：输入一张图片路径，返回其评分\u001b[39;00m\n\u001b[0;32m     16\u001b[0m test_image_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdog_pics/37401.jpg\u001b[39m\u001b[38;5;124m'\u001b[39m  \u001b[38;5;66;03m# 这里替换成您的图片路径\u001b[39;00m\n\u001b[1;32m---> 17\u001b[0m predicted_score \u001b[38;5;241m=\u001b[39m \u001b[43mpredict_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_image_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted score for the image: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_score\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m, in \u001b[0;36mpredict_score\u001b[1;34m(image_path)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mpredict_score\u001b[39m(image_path):\n\u001b[0;32m      3\u001b[0m     \u001b[38;5;66;03m# 加载并预处理图片\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m \u001b[43mload_image\u001b[49m(image_path)\n\u001b[0;32m      5\u001b[0m     img_array \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mexpand_dims(img_array, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)  \u001b[38;5;66;03m# 增加 batch 维度\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     \u001b[38;5;66;03m# 提取特征\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'load_image' is not defined"
     ]
    }
   ],
   "source": [
    "# 用训练好的模型预测评分\n",
    "def predict_score(image_path):\n",
    "    # 加载并预处理图片\n",
    "    img_array = load_image(image_path)\n",
    "    img_array = np.expand_dims(img_array, axis=0)  # 增加 batch 维度\n",
    "    \n",
    "    # 提取特征\n",
    "    features = feature_extractor.predict(img_array)\n",
    "    \n",
    "    # 预测评分\n",
    "    score = score_model.predict(features)\n",
    "    \n",
    "    return score[0][0]\n",
    "\n",
    "# 测试：输入一张图片路径，返回其评分\n",
    "test_image_path = 'dog_pics/37401.jpg'  # 这里替换成您的图片路径\n",
    "predicted_score = predict_score(test_image_path)\n",
    "print(f\"Predicted score for the image: {predicted_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "86180524-4fc9-4ff6-86f3-9ddd2b459927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 260ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 274ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 154ms/step\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step\n",
      "You prefer the second image.\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('animal_pics/google-advancedsearch-2.jpg')  # 将路径替换为实际图片路径\n",
    "img2 = cv2.imread('animal_pics/google-advancedsearch-7.jpg')\n",
    "\n",
    "# 将图片转换为数组\n",
    "img1 = cv2.resize(img1, (256, 256))  # 如果使用OpenCV，需要先调整图像大小\n",
    "img1 = img1 / 255.0  # 归一化到0-1范围\n",
    "img1 = np.expand_dims(img1, axis=0)  # 增加批次维度\n",
    "\n",
    "img2 = cv2.resize(img2, (256, 256))  # 如果使用OpenCV，需要先调整图像大小\n",
    "img2 = img2 / 255.0  # 归一化到0-1范围\n",
    "img2 = np.expand_dims(img2, axis=0)  # 增加批次维度\n",
    "\n",
    "def compare_images(img1, img2):\n",
    "    # 提取图片特征\n",
    "    features1 = model.predict(img1)  # 直接传入已调整的图片\n",
    "    features2 = model.predict(img2)\n",
    "    \n",
    "    # 使用评分模型来预测评分\n",
    "    score1 = score_model.predict(features1)\n",
    "    score2 = score_model.predict(features2)\n",
    "    \n",
    "    if score1 > score2:\n",
    "        return \"You prefer the first image.\"\n",
    "    else:\n",
    "        return \"You prefer the second image.\"\n",
    "\n",
    "# 假设img1和img2是你要比较的两张图片\n",
    "\n",
    "print(compare_images(img1, img2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7131b77-ab2a-47ef-b3fb-0f58e0ef1d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "classificationtry1",
   "language": "python",
   "name": "classificationtry1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
